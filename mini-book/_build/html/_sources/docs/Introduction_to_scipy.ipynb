{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # SciPy - Library of scientific algorithms for Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The SciPy framework builds on top of the low-level NumPy framework for multidimensional arrays, and provides a large number of higher-level scientific algorithms. Today we will discuss a few that are most useful for data science:\n",
    "\n",
    "* Integration ([scipy.integrate](http://docs.scipy.org/doc/scipy/reference/integrate.html))\n",
    "* Optimization ([scipy.optimize](http://docs.scipy.org/doc/scipy/reference/optimize.html))\n",
    "* Interpolation ([scipy.interpolate](http://docs.scipy.org/doc/scipy/reference/interpolate.html))\n",
    "* Linear Algebra ([scipy.linalg](http://docs.scipy.org/doc/scipy/reference/linalg.html))\n",
    "* Statistics ([scipy.stats](http://docs.scipy.org/doc/scipy/reference/stats.html))\n",
    "* File IO ([scipy.io](http://docs.scipy.org/doc/scipy/reference/io.html))\n",
    "\n",
    "In addition, you may wish to review Lecture 3 of Johanssen that covers others:\n",
    "\n",
    "* Special Functions ([scipy.special](http://docs.scipy.org/doc/scipy/reference/special.html))\n",
    "* Fourier Transforms ([scipy.fftpack](http://docs.scipy.org/doc/scipy/reference/fftpack.html))\n",
    "* Signal Processing ([scipy.signal](http://docs.scipy.org/doc/scipy/reference/signal.html))\n",
    "* Sparse Eigenvalue Problems ([scipy.sparse](http://docs.scipy.org/doc/scipy/reference/sparse.html))\n",
    "* Multi-dimensional image processing ([scipy.ndimage](http://docs.scipy.org/doc/scipy/reference/ndimage.html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can import the entire `scipy` module, or specific functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from scipy import linalg as la\n",
    "import numpy as np #we almost always need numpy too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Numerical integration: fixed data\n",
    "\n",
    "You can use the trapezoidal rule or Simpson's rule to integrate (x,y) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import trapz, simps\n",
    "\n",
    "x = np.linspace(1,100,100)\n",
    "x3 = x**3\n",
    "x3_integral = ((100**4)/4) - (1/4)\n",
    "\n",
    "x3_trapz = trapz(x3, x)\n",
    "x3_simps = simps(x3,x)\n",
    "\n",
    "print(x3_trapz)\n",
    "print(x3_simps)\n",
    "print(x3_integral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Numerical integration: quadrature\n",
    "\n",
    "The quadrature function allows integration of the form:\n",
    "\n",
    "$\\displaystyle \\int_a^b f(x) dx$\n",
    "\n",
    "and is the most accurate form of integration if `f(x)` is known. Scipy can do single, double, or triple integrals with `quad`, `dblquad` and `tplquad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import quad, dblquad, tplquad\n",
    "\n",
    "def f(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_lower = 1 # the lower limit of x\n",
    "x_upper = 100 # the upper limit of x\n",
    "\n",
    "val, abserr = quad(f, x_lower, x_upper)\n",
    "\n",
    "print(\"integral value = {}, absolute error = {}, real answer= {}\".format(val,abserr,x3_integral))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Argument passing can be handled with optional arguments or use the `args` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def f(x, n=3):\n",
    "    return x**n\n",
    "\n",
    "args = (3,)\n",
    "val, abserr = quad(f, x_lower, x_upper)\n",
    "\n",
    "print(val, abserr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Higher-dimensional integration works similarly, except that boundary \"curves\" have to be defined. This is a place where `lambda` functions are very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def integrand(x, y):\n",
    "    return np.exp(-x**2-y**2)\n",
    "\n",
    "x_lower = -np.inf  \n",
    "x_upper = np.inf #infinity can be used as a limit\n",
    "y_lower = 0\n",
    "y_upper = 10\n",
    "\n",
    "val, abserr = dblquad(integrand, x_lower, x_upper, lambda x: y_lower, lambda x: y_upper)\n",
    "\n",
    "print(val, abserr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpolation\n",
    "\n",
    "Interpolation is simple and convenient in scipy: The `interp1d` function, when given arrays describing X and Y data, returns and object that behaves like a function that can be called for an arbitrary value of x (in the range covered by X), and it returns the corresponding interpolated y value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from scipy import randn\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "n = np.arange(0, 10)  \n",
    "x = np.linspace(0, 9, 100)\n",
    "\n",
    "y_meas = f(n) + 0.1 * randn(len(n)) # simulate measurement with noise\n",
    "y_real = f(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "ax.plot(n, y_meas, 'bs', label='noisy data')\n",
    "ax.plot(x, y_real, 'k', lw=2, label='true function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "linear_interpolation = interp1d(n, y_meas, kind='linear')\n",
    "y_interp1 = linear_interpolation(x)\n",
    "\n",
    "cubic_interpolation = interp1d(n, y_meas, kind='cubic')\n",
    "y_interp2 = cubic_interpolation(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "ax.plot(n, y_meas, 'bs', label='noisy data')\n",
    "ax.plot(x, y_real, 'k', lw=2, label='true function')\n",
    "ax.plot(x, y_interp1, 'r', label='linear interp')\n",
    "ax.plot(x, y_interp2, 'g', label='cubic interp')\n",
    "ax.legend(loc=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization\n",
    "\n",
    "Optimization (finding minima or maxima of a function) is a large field in mathematics, and optimization of complicated functions or in many variables can be rather involved. Here we will only look at a few very simple cases. For a more detailed introduction to optimization with SciPy see: http://scipy-lectures.github.com/advanced/mathematical_optimization/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Finding a minima\n",
    "\n",
    "Let's first look at how to find the minima of a simple function of a single variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "def f(x):\n",
    "    return 4*x**3 + (x-2)**2 + x**4\n",
    "\n",
    "fig, ax  = plt.subplots()\n",
    "x = np.linspace(-5, 3, 100)\n",
    "ax.plot(x, f(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are many types of optimizers available. We will use the common `BFGS` and `CG` optimizers here, but you can read more in the [documentation](https://docs.scipy.org/doc/scipy/reference/optimize.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "x_min = minimize(f, 0.5, method='CG')\n",
    "# method?\n",
    "# output?\n",
    "print(x_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Solving an equation\n",
    "\n",
    "* solve equations using root finding by expressing the equation as $f(x) = 0$ \n",
    "* use the `fsolve` function which requires an initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    return np.sin(3*x)*(1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(figsize=(10,4))\n",
    "x = np.linspace(1, 10, 200)\n",
    "y = f(x)\n",
    "ax.plot(x, y)\n",
    "ax.plot([0,11],[0,0],'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "optimize.fsolve(f, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistics\n",
    "\n",
    "The `scipy.stats` module contains a large number of statistical distributions, statistical functions and tests. For a complete documentation of its features, see http://docs.scipy.org/doc/scipy/reference/stats.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# create a (continous) random variable with normal distribution\n",
    "Y = stats.norm()\n",
    "print(Y)\n",
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5,5,100)\n",
    "\n",
    "fig, axes = plt.subplots(3,1, sharex=True) #< we will get to this later...\n",
    "\n",
    "# plot the probability distribution function (PDF)\n",
    "axes[0].plot(x, Y.pdf(x))\n",
    "\n",
    "# plot the commulative distributin function (CDF)\n",
    "axes[1].plot(x, Y.cdf(x));\n",
    "\n",
    "# plot histogram of 1000 random realizations of the stochastic variable Y\n",
    "axes[2].hist(Y.rvs(size=1000), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We can also create a Poisson distribution (this is used in modeling the frequency of random events)\n",
    "\n",
    "X = stats.poisson(3) # poisson distribution with an expectation value of 4\n",
    "\n",
    "n = np.arange(0,20)\n",
    "\n",
    "fig, axes = plt.subplots(3,1, sharex=True)\n",
    "\n",
    "# plot the probability mass function (PMF)\n",
    "axes[0].step(n, X.pmf(n))\n",
    "\n",
    "# plot the commulative distribution function (CDF)\n",
    "axes[1].step(n, X.cdf(n))\n",
    "\n",
    "# plot histogram of 1000 random realizations of the stochastic variable X\n",
    "axes[2].hist(X.rvs(size=1000),bins=n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can easily calculate the statistics of these distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y.mean(), Y.std(), Y.var()) # normal distribution\n",
    "\n",
    "print(X.mean(), X.std(), X.var()) # poission distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Statistical tests\n",
    "\n",
    "We can use a t-test to test if two sets of (independent) random data have the same mean. The null hypothesis is that the two sets of data have the *same mean*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "t_statistic, p_value = stats.ttest_ind(Y.rvs(size=1000)+3, X.rvs(size=1000),equal_var=False)\n",
    "#note that this test assumes equal variance by default.\n",
    "\n",
    "print(\"t-statistic =\", t_statistic)\n",
    "print(\"p-value =\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can also use a 1-sample t-test to test if the mean of a single sample of data has mean 0.1 (the true mean is 0.0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "t_statistic, p_value = stats.ttest_1samp(Y.rvs(size=1000), 0.1)\n",
    "print(\"t-statistic =\", t_statistic)\n",
    "print(\"p-value =\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear algebra\n",
    "\n",
    "The linear algebra module of scipy contains more advanced matrix-related functions than numpy. Here we will look at:\n",
    "\n",
    "* linear equation solving\n",
    "* eigenvalue solvers\n",
    "\n",
    "However, numerous other advanced features are available. The detailed documetation is available at: http://docs.scipy.org/doc/scipy/reference/linalg.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Linear equation systems\n",
    "\n",
    "Linear equation systems on the matrix form\n",
    "\n",
    "$A x = b$\n",
    "\n",
    "where $A$ is a matrix and $x,b$ are vectors can be solved like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import solve\n",
    "\n",
    "N = 3\n",
    "A = np.random.rand(N,N)\n",
    "b = np.random.rand(N)\n",
    "\n",
    "x = solve(A, b)\n",
    "\n",
    "print(x)\n",
    "# check\n",
    "np.dot(A, x) - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can also do the same with\n",
    "\n",
    "$A X = B$\n",
    "\n",
    "where $A, B, X$ are matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A = np.random.rand(N,N)\n",
    "B = np.random.rand(N,N)\n",
    "\n",
    "X = solve(A, B)\n",
    "# check\n",
    "np.dot(A, X) - B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Eigenvalues and eigenvectors\n",
    "\n",
    "The eigenvalue problem for a matrix $A$:\n",
    "\n",
    "$\\displaystyle A v_n = \\lambda_n v_n$\n",
    "\n",
    "where $v_n$ is the $n$th eigenvector and $\\lambda_n$ is the $n$th eigenvalue.\n",
    "\n",
    "To calculate eigenvalues of a matrix, use the `eigvals` and for calculating both eigenvalues and eigenvectors, use the function `eig`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import eigvals, eig\n",
    "evals = eigvals(A)\n",
    "print(evals)\n",
    "\n",
    "evals, evecs = eig(A)\n",
    "print(evals)\n",
    "print(evecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\displaystyle A v_n = \\lambda_n v_n$\n",
    "\n",
    "The eigenvectors corresponding to the $n$th eigenvalue (stored in `evals[n]`) is the $n$th *column* in `evecs`, i.e., `evecs[:,n]`. To verify this, let's try mutiplying eigenvectors with the matrix and compare to the product of the eigenvector and the eigenvalue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = 2\n",
    "\n",
    "np.dot(A, evecs[:,n]) - evals[n] * evecs[:,n]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
