

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>7.5. Clustering &#8212; Medford Group Graduate Training</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/ML_2_4_Clustering';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7.6. Generative Models" href="ML_2_5_Generative_Models.html" />
    <link rel="prev" title="7.4. Alternate classification methods" href="ML_2_3_Alternate_Classification_Models.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/MedfordLogo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/MedfordLogo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Medford Group Graduate Training
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">VIP</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="VIP_Info.html">VIP Materials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="VIP_syllabus.html">Course Description</a></li>





<li class="toctree-l2"><a class="reference internal" href="VIP_Overview.html">Big Data &amp; Quantum Mechanics</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Training Materials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="Basic_Python_Tools.html">1. Introduction to Basic Python Tools</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="Introduction_to_Python_programming.html">1.2. Introduction to Python programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Introduction_to_numpy.html">1.3. Numpy -  multidimensional data arrays</a></li>
<li class="toctree-l2"><a class="reference internal" href="Introduction_to_scipy.html">1.4. SciPy - Library of scientific algorithms for Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="Introduction_to_plotting_in_Python.html">1.5. matplotlib - Plotting in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exercises_python.html">1.6. Exercises</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Manipulating_Atoms_in_Python.html">2. Introduction to Manipulating Atoms in Python</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="Intro_to_ASE_Building_Structures.html">2.2. Intro to Building Structures with ASE</a></li>
<li class="toctree-l2"><a class="reference internal" href="Intro_to_ASE_Calculators.html">2.3. Intro to ASE Calculators</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exercises_ASE_intro.html">2.4. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exercises_ASE_calcs.html">2.5. Exercises</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Intro_to_Linux_HPC.html">3. Introduction to Linux and High-Performance Computing</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="Exercises_linux.html">3.3. Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Intro_to_Density_Functional_Theory.html">4. Introduction to Density Functional Theory</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Applications_of_Density_Functional_Theory.html">5. Applications of Density Functional Theory</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="Adsorption_energy_calculation_in_QE.html">5.2. Adsorption energy calculation using DFT</a></li>
<li class="toctree-l2"><a class="reference internal" href="Adsorption_energy_calculation_in_SPARC.html">5.3. Adsorption energy from DFT</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exercises_DFT_applications.html">5.4. Exercises</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Intro_to_Regression_and_High_Dimensional_Data.html">6. Intro to Regression and High Dimensional Data</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="ML_1_1_Non-parametric_Models.html">6.2. Non-Parametric Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="ML_1_2_Complexity_Optimization.html">6.3. Complexity Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="ML_1_3_High_Dimensional_Data.html">6.4. High Dimensional Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="ML_1_4_Dimensionality_Reduction.html">6.5. Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exercises_ML_basics_Pt1.html">6.6. Exercises</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="Intro_to_Classification_and_Generative_Models.html">7. Intro to Classification and Generative Models</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ML_2_1_Classification_Basics.html">7.2. Classification Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="ML_2_2_Generalized_Linear_Models.html">7.3. Generalized Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="ML_2_3_Alternate_Classification_Models.html">7.4. Alternate classification methods</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">7.5. Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="ML_2_5_Generative_Models.html">7.6. Generative Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exercises_ML_basics_Pt2.html">7.7. Exercises</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="Appendix.html">Appendix</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="Literature_Searches.html">Basics of Searching and Reading Scientific Literature</a></li>
<li class="toctree-l2"><a class="reference internal" href="Create_DFT_Environments.html">Create DFT Environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="Gas_formation_energy_calculation_in_SPARC.html">Gas formation energy calculation using DFT</a></li>
<li class="toctree-l2"><a class="reference internal" href="Referencing_Binding_Energies.html">Referencing Binding Energies</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/docs/ML_2_4_Clustering.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Clustering</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-overview">7.5.1. Clustering Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">7.5.1.1. Problem statement</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-problems-algorithms">7.5.1.2. Types of problems/algorithms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy-and-distance-metrics">7.5.2. Accuracy and distance metrics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-preparation">7.5.3. Dataset Preparation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-maximization-models">7.5.4. Expectation-maximization models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means">7.5.4.1. k-means</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion-which-of-these-clusters-might-be-outliers">7.5.4.2. Discussion: Which of these clusters might be outliers?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-mixture-models">7.5.4.3. Gaussian mixture models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-step">7.5.4.3.1. Expectation step:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#maximization-step">7.5.4.3.2. Maximization step:</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-plot-the-silhouette-score-as-a-function-of-number-of-clusters-for-a-gmm-model-on-the-pca-dataset">7.5.4.4. Example: Plot the silhouette score as a function of number of clusters for a GMM model on the PCA dataset</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#density-based-models">7.5.5. Density-based models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-shift-algorithm">7.5.5.1. Mean shift algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion-what-happens-if-the-initial-guess-is-very-far-away-from-a-cluster">7.5.5.2. Discussion: What happens if the initial guess is very far away from a cluster?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion-how-can-we-modify-the-algorithm-to-find-more-clusters">7.5.5.3. Discussion: How can we modify the algorithm to find more clusters?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dbscan">7.5.5.4. DBSCAN</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hierarchical-models">7.5.6. Hierarchical models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dendrograms">7.5.6.1. Dendrograms</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#agglomerative-hierarchical-clustering">7.5.6.2. Agglomerative hierarchical clustering</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;../settings/plot_style.mplstyle&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">clrs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;#003057&#39;</span><span class="p">,</span> <span class="s1">&#39;#EAAA00&#39;</span><span class="p">,</span> <span class="s1">&#39;#4B8B9B&#39;</span><span class="p">,</span> <span class="s1">&#39;#B3A369&#39;</span><span class="p">,</span> <span class="s1">&#39;#377117&#39;</span><span class="p">,</span> <span class="s1">&#39;#1879DB&#39;</span><span class="p">,</span> <span class="s1">&#39;#8E8B76&#39;</span><span class="p">,</span> <span class="s1">&#39;#F5D580&#39;</span><span class="p">,</span> <span class="s1">&#39;#002233&#39;</span><span class="p">,</span> <span class="s1">&#39;#808080&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="clustering">
<h1><span class="section-number">7.5. </span>Clustering<a class="headerlink" href="#clustering" title="Permalink to this heading">#</a></h1>
<p>Another common strategy for exploring datasets is to find “clusters” of similar datapoints. This is an unsupervised approach that can help identify patterns in low or high dimensions. This lecture will cover basic considerations and concepts in clustering data, and introduce a few basic classes of algorithms along with examples.</p>
<section id="clustering-overview">
<h2><span class="section-number">7.5.1. </span>Clustering Overview<a class="headerlink" href="#clustering-overview" title="Permalink to this heading">#</a></h2>
<section id="problem-statement">
<h3><span class="section-number">7.5.1.1. </span>Problem statement<a class="headerlink" href="#problem-statement" title="Permalink to this heading">#</a></h3>
<p>Clustering algorithms seek to identify data points that are similar to each other based on a set of descriptive features.</p>
<p>Clustering algorithms are <strong>unsupervised</strong> since they do not include output labels. The goal is to extract insight about the dataset based on its inherent structure, rather than to build a model that predicts an output.</p>
<p>Some common uses for clustering include:</p>
<ul class="simple">
<li><p>data compression</p></li>
<li><p>group/class assignment</p></li>
<li><p>searching high-dimensional data</p></li>
<li><p>feature identification</p></li>
<li><p>learning probability distributions</p></li>
<li><p>outlier detection</p></li>
</ul>
<p>We will discuss some of these applications, but the same algorithms can be applied in many different ways to solve different problems that we may not discuss.</p>
</section>
<section id="types-of-problems-algorithms">
<h3><span class="section-number">7.5.1.2. </span>Types of problems/algorithms<a class="headerlink" href="#types-of-problems-algorithms" title="Permalink to this heading">#</a></h3>
<p>There are a few key types of clustering algorithms:</p>
<p><strong>Expectation-maximization</strong> algorthims iteratively compute “expected” clusters and then “maximize” the parameters of the cluster to optimize the expectations. This is somewhat similar to an iterative version of a generalized linear classification algorithm: “classes” are assigned, then boundaries are found to optimize a cost function based on these classes. After this optimization the new class boundaries are used to assign classes again, and the optimization is repeated with new “class” labels.</p>
<p><strong>Density-based</strong> algorithms utilize local information about data points to identify regions where the data has similar density. Regions where there is substantially lower density of data form boundaries between these clusters. This is somewhat similar to k-nearest neighbors where classes are defined by local environments.</p>
<p><strong>Hierarchical</strong> algorithms map out the full network of connectivity within a dataset, then use a variable distance cutoff to assign clusters. These algorithms can be understood visually through a dendrogram, and have relatively few hyperparameters but they are more computationally demanding.</p>
<p>A few considerations when selecting a clustering algorithm:</p>
<ul class="simple">
<li><p>Some algorithms require defining the number of clusters explicitly (e.g. most expectation-maximization algorithms) while others find this implicitly based on choice of hyperparameters (e.g. density-based or hierarchical)</p></li>
<li><p>Some algorithms allow <strong>mixed membership</strong> where points can belong to multiple clusters based on probabilities.</p></li>
<li><p>Some algorithms can identify/ignore outliers/noise (e.g. density-based), while others attempt to assign clusters to all points (e.g. expectation-maximization and hierarchical).</p></li>
</ul>
</section>
</section>
<section id="accuracy-and-distance-metrics">
<h2><span class="section-number">7.5.2. </span>Accuracy and distance metrics<a class="headerlink" href="#accuracy-and-distance-metrics" title="Permalink to this heading">#</a></h2>
<p>Computing the accuracy of unsupervised models is difficult because there is no “right answer”. However, it is possible to compute some quantitative metrics based on the concept of a cluster.</p>
<ul class="simple">
<li><p><strong>Silhouette score</strong> is defined for <em>each point</em> and is related to two distances:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(a\)</span> is the average distance between a point and all other points in its cluster</p></li>
<li><p><span class="math notranslate nohighlight">\(b\)</span> is the average distance between a point and the points in the next nearest cluster</p></li>
<li><p><span class="math notranslate nohighlight">\(S = \frac{b-a}{max(a,b)}\)</span> is the silhoutte score</p></li>
<li><p><span class="math notranslate nohighlight">\(S = -1\)</span> implies totally incorrect, <span class="math notranslate nohighlight">\(S=1\)</span> implies totally correct</p></li>
<li><p>Works best for dense, well-separated clusters</p></li>
<li><p>Does not work well for density-based clusters (e.g. DBSCAN)</p></li>
</ul>
</li>
</ul>
<p>The silhouette score can help identify individual points that are not well-clustered, or an average/max silhouette score can be used to evaluate the quality of the entire clustering model. Other metrics can be used to evaluate the overall model:</p>
<ul class="simple">
<li><p><strong>Variance ratio criterion</strong> or “Calinski-Harabasz score” is related to the “within class” variance (similar to intra-class variance for classificaiton) and the “between class” variance (similar to the interclass variance for classification). The mathematical definition is available <a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1080/03610927408827101">here</a> but is beyond the scope of this course.</p>
<ul>
<li><p>Variance ratio will be higher for dense and well-separated clusters</p></li>
<li><p>Not bounded so it can be difficult to know what is “good” and what is “bad”</p></li>
<li><p>Does not work well for density-based clusters (e.g. DBSCAN)</p></li>
</ul>
</li>
</ul>
<p>These approaches can be utilized to identify hyperparameters such as the number of clusters in the case where there is no <em>a priori</em> expectation about the number of clusters.</p>
<ul class="simple">
<li><p><strong>Information Criteria</strong> The concept of “information criteria” can also be computed for some clustering models where there is an underlying probability distribution. Instead of using the error between the model and the predictions, as we did for supervised models, the “log-likelihood” that the data is described by the underlying model can be computed. The details are beyond the scope of this course, but we will use built-in functions to compute information criteria for some clustering models. This is a great way of assessing the quality of a model, but it is only possible for a limited class of clustering models.</p></li>
<li><p><strong>Classification Metrics</strong> Another common technique is to use clustering for classification problems. In this case the error metrics from classification can be applied (e.g. confusion matrices, precision, recall, etc.). The comparison of clustering and classification can provide insight into how well the classes are captured by proximity in the feature space. The downside is that this is only possible if labels are known, and is not truly an unsupervised evaluation of the data.</p></li>
</ul>
<p>Finally, it is worth noting that essentially all clustering algorithms rely on some form of <strong>distance metric</strong>. The way that distance is defined can have substantial impact on how clustering analyses perform. Some common choices to compute the distance between two points <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>:</p>
<ul class="simple">
<li><p>Euclidean distance (<span class="math notranslate nohighlight">\(L_2\)</span> norm): <span class="math notranslate nohighlight">\(D_{ij} = \sqrt{sum((\vec{x}_i - \vec{x}_j)^2)}\)</span></p></li>
<li><p>Manhattan distance (<span class="math notranslate nohighlight">\(L_1\)</span> norm): <span class="math notranslate nohighlight">\(D_{ij} = sum(abs(\vec{x}_i - \vec{x}_j))\)</span></p></li>
<li><p>Chebyshev distance (<span class="math notranslate nohighlight">\(L_\infty\)</span> norm): <span class="math notranslate nohighlight">\(D_{ij} = max(abs(\vec{x}_i - \vec{x}_j))\)</span></p></li>
<li><p>Minkowsky distance (<span class="math notranslate nohighlight">\(L_P\)</span> norm): <span class="math notranslate nohighlight">\(D_{ij} = (sum((\vec{x}_i - \vec{x}_j)^P)^{1/P}\)</span></p></li>
</ul>
<p>It is also possible to define a weighted distance metric that can implicitly standardize the data, or weight nearby points much higher than far away points. An example is the Mahalanobis distance:</p>
<ul class="simple">
<li><p>Mahalanobis distance: <span class="math notranslate nohighlight">\(D_{ij} = (\vec{x}_i - \vec{\mu})^T \underline{\underline{C}}^{-1} (\vec{x}_j - \vec{\mu})\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mu\)</span> is the mean vector</p></li>
<li><p><span class="math notranslate nohighlight">\(\underline{\underline{C}}\)</span> is the covariance matrix</p></li>
</ul>
</li>
<li><p>Kernel distance: <span class="math notranslate nohighlight">\(D_{ij} = (\vec{x}_i)^T \underline{\underline{K}} (\vec{x}_j)\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\underline{\underline{K}}\)</span> is a kernel-based weight matrix</p></li>
</ul>
</li>
</ul>
<p>For simplicity we will typically default to Euclidean distance in most examples; however, changing distance metrics can substantially improve performance in real problems so it is worthwhile to experiment. This is usually as simple as changing a keyword for <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> models, or writing a short function to compute the necessary distance.</p>
<p>It is also useful to consider the <strong>cophenetic correlation coefficient</strong> when dealing with different distance metrics or “linkages” in hierarchical representations of high-dimensional data. This can be considered as a comparison between distance metrics and the Euclidean distance. This will be discussed more later.</p>
</section>
<section id="dataset-preparation">
<h2><span class="section-number">7.5.3. </span>Dataset Preparation<a class="headerlink" href="#dataset-preparation" title="Permalink to this heading">#</a></h2>
<p>In this lecture we will work with the Dow chemical data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data/impurity_dataset-training.xlsx&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">is_real_and_finite</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isreal</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>

<span class="n">all_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span><span class="o">.</span><span class="n">values</span> <span class="c1">#drop the first column (date)</span>
<span class="n">numeric_map</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span><span class="o">.</span><span class="n">applymap</span><span class="p">(</span><span class="n">is_real_and_finite</span><span class="p">)</span>
<span class="n">real_rows</span> <span class="o">=</span> <span class="n">numeric_map</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">values</span> <span class="c1">#True if all values in a row are real numbers</span>
<span class="n">X_dow</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_data</span><span class="p">[</span><span class="n">real_rows</span><span class="p">,:</span><span class="o">-</span><span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">)</span> <span class="c1">#drop the last 5 cols that are not inputs</span>
<span class="n">y_dow</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_data</span><span class="p">[</span><span class="n">real_rows</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
<span class="n">y_dow</span> <span class="o">=</span> <span class="n">y_dow</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_dow</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_dow</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(10297, 40) (10297, 1)
</pre></div>
</div>
</div>
</div>
<p>We know that the features have different units, so we can standardize them to give them comparable scales, and we will take every 5th data point to speed things up:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_dow</span> <span class="o">-</span> <span class="n">X_dow</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="n">X_dow</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[::</span><span class="mi">5</span><span class="p">]</span> <span class="c1"># take every 5th datapoint</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2060, 40)
</pre></div>
</div>
</div>
</div>
<p>Next we will apply a few different dimensionality reduction algorithms so that we can see how different clustering algorithms perform on different low-dimensional representations. Note that clustering algorithms generally work the same in high-dimensions, but it is much more difficult to get intuition if we can’t visualize the results.</p>
<p>This is a common strategy in exploratory data analysis: apply dimensional reduction to get some intuition about the data in low dimensions, then try to see if the same intuition holds in the full high-dimensional space.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span><span class="p">,</span> <span class="n">KernelPCA</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">Isomap</span><span class="p">,</span> <span class="n">TSNE</span>

<span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span><span class="p">)</span>
<span class="o">%</span><span class="k">time</span> X_pca = pca.fit_transform(X)

<span class="n">kpca</span> <span class="o">=</span> <span class="n">KernelPCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span><span class="p">,</span> <span class="n">kernel</span> <span class="o">=</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="o">%</span><span class="k">time</span> X_kpca = kpca.fit_transform(X)

<span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span><span class="p">)</span>
<span class="o">%</span><span class="k">time</span> X_tsne = tsne.fit_transform(X)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 20.4 ms, sys: 3.04 ms, total: 23.4 ms
Wall time: 15.1 ms
CPU times: user 470 ms, sys: 42.2 ms, total: 512 ms
Wall time: 283 ms
CPU times: user 53.4 s, sys: 3.27 s, total: 56.7 s
Wall time: 20.5 s
</pre></div>
</div>
</div>
</div>
<p>We can plot the different results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_pca</span><span class="p">,</span> <span class="n">X_kpca</span><span class="p">,</span> <span class="n">X_tsne</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;PCA&#39;</span><span class="p">,</span> <span class="s1">&#39;Kernel PCA&#39;</span><span class="p">,</span> <span class="s1">&#39;TSNE&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">X_i</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_i</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_i</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/a63b92438e5feb232f0ea688f4cb13536ebe2675cae9279386c4c64d719d7481.png" src="../_images/a63b92438e5feb232f0ea688f4cb13536ebe2675cae9279386c4c64d719d7481.png" />
</div>
</div>
<p>We can see that the structure of the low-dimensional representations depends on the technique we use. We will use these datasets as examples for various types of clustering models to see how we might end up with different “clusters” of chemical process parameters depending on the dimensional reduction and clustering technique we use.</p>
<p>In a real scenario, we would want to go back to the original data and process parameters to see if these clusters align with our intuition as engineers. For example, clusters might represent different steady-states or set-points for the process.</p>
</section>
<section id="expectation-maximization-models">
<h2><span class="section-number">7.5.4. </span>Expectation-maximization models<a class="headerlink" href="#expectation-maximization-models" title="Permalink to this heading">#</a></h2>
<section id="k-means">
<h3><span class="section-number">7.5.4.1. </span>k-means<a class="headerlink" href="#k-means" title="Permalink to this heading">#</a></h3>
<p>The k-means algorithm is the simplest and most intuitive clustering algorithm. It performs remarkably well under a number of assumptions:</p>
<ul class="simple">
<li><p>Number of clusters are known</p></li>
<li><p>Clusters are roughly spherical</p></li>
<li><p>Clusters are separated by linear boundaries</p></li>
</ul>
<p>Even if these assumptions are violated, it often works anyway, especially in high dimensions (the “blessing” of dimensionality).</p>
<p>The k-means algorithm works using the principal of <strong>expectation-maximization</strong>. This is an iterative type of algorithm that contains two basic steps:</p>
<ul class="simple">
<li><p>Expectation: Assign points based on some “expectation” metric.</p></li>
<li><p>Maximization: Revise expectations based on maximizing a fitness metric.</p></li>
</ul>
<p>In the case of k-means we:</p>
<ul class="simple">
<li><p>Expect that points close to the center of a cluster belong to that cluster</p></li>
<li><p>Maximize the proximity of points to the center of a cluster by moving the center</p></li>
</ul>
<p>This process is iterated until convergence.</p>
<p>We will create a simple “toy” implementation of k-means, and see how it works for the Dow dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">dist</span><span class="p">(</span><span class="n">pt1</span><span class="p">,</span> <span class="n">pt2</span><span class="p">):</span>
    <span class="c1"># Euclidean distance between two points</span>
    <span class="c1"># Note that this can also be performed with np.linalg.norm(pt1-pt2)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">([(</span><span class="n">xi</span> <span class="o">-</span> <span class="n">yi</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">xi</span><span class="p">,</span> <span class="n">yi</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pt1</span><span class="p">,</span> <span class="n">pt2</span><span class="p">)]))</span>

<span class="k">def</span> <span class="nf">expected_assignment</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span> <span class="n">cluster_centers</span><span class="p">):</span>
    <span class="c1"># Expectation: find the closest points to each cluster center</span>
    <span class="n">dists</span> <span class="o">=</span> <span class="p">[</span><span class="n">dist</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span> <span class="n">ci</span><span class="p">)</span> <span class="k">for</span> <span class="n">ci</span> <span class="ow">in</span> <span class="n">cluster_centers</span><span class="p">]</span> <span class="c1">#&lt;- find distance to each center</span>
    <span class="n">min_index</span> <span class="o">=</span> <span class="n">dists</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">dists</span><span class="p">))</span> <span class="c1">#&lt;- find the index (cluster) with the minimum dist</span>
    <span class="k">return</span> <span class="n">min_index</span>

<span class="k">def</span> <span class="nf">new_centers</span><span class="p">(</span><span class="n">cluster_points</span><span class="p">,</span> <span class="n">centers</span><span class="p">):</span>
    <span class="c1"># Maximization: maximize the proximity of centers to points in a cluster</span>
    <span class="n">centers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">centers</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cluster_points</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">ci</span> <span class="o">!=</span> <span class="p">[]:</span>
            <span class="n">centers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ci</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">centers</span>
</pre></div>
</div>
</div>
</div>
<p>Now we need an “initial guess” of cluster centers and we can apply the algorithm to a toy dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">X_pca</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#cluster_centers = ([-0.5,0], [0.5,0])</span>
<span class="n">cluster_centers</span> <span class="o">=</span> <span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cluster_centers</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="s1">&#39;20&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">clrs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Initial Guess&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2060, 2)
</pre></div>
</div>
<img alt="../_images/0362374f6cf24bf097da17e9cc795f61f4827add94c433b3d51e1f6823159a3b.png" src="../_images/0362374f6cf24bf097da17e9cc795f61f4827add94c433b3d51e1f6823159a3b.png" />
</div>
</div>
<p>Run the cell below repeatedly to see how the algorithm converges. Re-run the cell above to re-start the algorithm.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">old_centers</span> <span class="o">=</span> <span class="n">cluster_centers</span>

<span class="c1"># Which cluster do we &quot;expect&quot; each point to belong to?</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="p">[[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]]</span>
<span class="k">for</span> <span class="n">pt</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
    <span class="n">cluster_idx</span> <span class="o">=</span> <span class="n">expected_assignment</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span> <span class="n">cluster_centers</span><span class="p">)</span>
    <span class="n">clusters</span><span class="p">[</span><span class="n">cluster_idx</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
    
<span class="c1"># What centers best represent these new assignments?</span>
<span class="n">cluster_centers</span> <span class="o">=</span> <span class="n">new_centers</span><span class="p">(</span><span class="n">clusters</span><span class="p">,</span> <span class="n">cluster_centers</span><span class="p">)</span>

<span class="c1"># Plot new assignments</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">pt</span> <span class="ow">in</span> <span class="n">ci</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pt</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Plot old centers</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">old_centers</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="s1">&#39;20&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">markeredgecolor</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>

<span class="c1"># Plot new centers</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cluster_centers</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ci</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="s1">&#39;20&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;k-Means Clustering - 1st Run&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-0.88397179 -0.09374578]
[17.88903744  1.89714391]
[100, 100]
</pre></div>
</div>
<img alt="../_images/5371ff5c2aab41760c599545896a5c56a459cedd5470f190971ef64f0e1639e7.png" src="../_images/5371ff5c2aab41760c599545896a5c56a459cedd5470f190971ef64f0e1639e7.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">old_centers</span> <span class="o">=</span> <span class="n">cluster_centers</span>
    
<span class="n">clusters</span> <span class="o">=</span> <span class="p">[[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]]</span>
<span class="k">for</span> <span class="n">pt</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
    <span class="n">cluster_idx</span> <span class="o">=</span> <span class="n">expected_assignment</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span> <span class="n">cluster_centers</span><span class="p">)</span>
    <span class="n">clusters</span><span class="p">[</span><span class="n">cluster_idx</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
    
<span class="n">cluster_centers</span> <span class="o">=</span> <span class="n">new_centers</span><span class="p">(</span><span class="n">clusters</span><span class="p">,</span> <span class="n">cluster_centers</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">pt</span> <span class="ow">in</span> <span class="n">ci</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pt</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
        
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">old_centers</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="s1">&#39;20&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cluster_centers</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ci</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="s1">&#39;20&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;k-Means Clustering - 2nd Run&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-0.77233592  0.03861822]
[25.74453066 -1.28727407]
[100, 100]
</pre></div>
</div>
<img alt="../_images/d87e1c9877e69e7787503ac96eeca7c6b5539b0b2bfb242814c45a32eee3df2e.png" src="../_images/d87e1c9877e69e7787503ac96eeca7c6b5539b0b2bfb242814c45a32eee3df2e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">old_centers</span> <span class="o">=</span> <span class="n">cluster_centers</span>
    
<span class="n">clusters</span> <span class="o">=</span> <span class="p">[[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]]</span>
<span class="k">for</span> <span class="n">pt</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
    <span class="n">cluster_idx</span> <span class="o">=</span> <span class="n">expected_assignment</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span> <span class="n">cluster_centers</span><span class="p">)</span>
    <span class="n">clusters</span><span class="p">[</span><span class="n">cluster_idx</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
    
<span class="n">cluster_centers</span> <span class="o">=</span> <span class="n">new_centers</span><span class="p">(</span><span class="n">clusters</span><span class="p">,</span> <span class="n">cluster_centers</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">pt</span> <span class="ow">in</span> <span class="n">ci</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pt</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
        
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">old_centers</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="s1">&#39;20&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cluster_centers</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ci</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="s1">&#39;20&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;k-Means Clustering - 3rd Run&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-0.73658236  0.06425897]
[27.89284524 -2.43335379]
[100, 100]
</pre></div>
</div>
<img alt="../_images/160841573d46d4ae3a39e8ce4df3bbe28167990ce3aa1b6d2b9c9fc6c8943052.png" src="../_images/160841573d46d4ae3a39e8ce4df3bbe28167990ce3aa1b6d2b9c9fc6c8943052.png" />
</div>
</div>
<p>In practice it is more efficient to utilize the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> implementation of <code class="docutils literal notranslate"><span class="pre">KMeans</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X_pca</span> <span class="c1">#scikit-learn is much more efficient, so we can run it on the whole datset</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span><span class="p">)</span><span class="c1">#, random_state=random_state)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">y_predict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">centers</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cluster_centers_</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">y_predict</span><span class="p">])</span>
<span class="k">for</span> <span class="n">center</span> <span class="ow">in</span> <span class="n">centers</span><span class="p">:</span>
    <span class="n">x_i</span> <span class="o">=</span> <span class="n">center</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y_i</span> <span class="o">=</span> <span class="n">center</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">y_i</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
    
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;k-Means for PCA&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ae4ca217a7d7a87c84b8fb99e4e333c67d71b691235def0c1063f6399605c688.png" src="../_images/ae4ca217a7d7a87c84b8fb99e4e333c67d71b691235def0c1063f6399605c688.png" />
</div>
</div>
<p>We can apply the same algorithm to other dimensional reduction techniques:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_pca</span><span class="p">,</span> <span class="n">X_kpca</span><span class="p">,</span> <span class="n">X_tsne</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;PCA&#39;</span><span class="p">,</span> <span class="s1">&#39;Kernel PCA&#39;</span><span class="p">,</span> <span class="s1">&#39;TSNE&#39;</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">X_i</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_i</span><span class="p">)</span>
    <span class="n">y_predict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_i</span><span class="p">)</span>
    <span class="n">centers</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cluster_centers_</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_i</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_i</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">y_predict</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">center</span> <span class="ow">in</span> <span class="n">centers</span><span class="p">:</span>
        <span class="n">x_i</span> <span class="o">=</span> <span class="n">center</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y_i</span> <span class="o">=</span> <span class="n">center</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">y_i</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ed8cfc054902742f6a103625058a2bbb7d8ee2300b0aa9ec90b32f3e222c44e5.png" src="../_images/ed8cfc054902742f6a103625058a2bbb7d8ee2300b0aa9ec90b32f3e222c44e5.png" />
</div>
</div>
</section>
<section id="discussion-which-of-these-clusters-might-be-outliers">
<h3><span class="section-number">7.5.4.2. </span>Discussion: Which of these clusters might be outliers?<a class="headerlink" href="#discussion-which-of-these-clusters-might-be-outliers" title="Permalink to this heading">#</a></h3>
<blockquote>
<div><p>The navy-colored cluster on the PCA plot could be an outlier. It has different patterns as compared to other clusters, but we cannot ensure whether they are actual outliers. To check this, it is good to go back and look the original data. Moreover, some other outliers can be identified from Kernel PCA and TSNE if you increase <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> to a bigger number.</p>
</div></blockquote>
</section>
<section id="gaussian-mixture-models">
<h3><span class="section-number">7.5.4.3. </span>Gaussian mixture models<a class="headerlink" href="#gaussian-mixture-models" title="Permalink to this heading">#</a></h3>
<p>Gaussian mixture models, or GMM’s, are another clustering approach based on expectation maximization. The approach is to model each cluster as a Gaussian distribution, and to model the entire dataset as a mixture of Gaussians. Mathematically:</p>
<p><span class="math notranslate nohighlight">\( P(\vec{x}) = \sum_k \phi_k \mathcal{N}(\vec{x}, \vec{\mu}, \vec{\sigma})\)</span></p>
<p>where <span class="math notranslate nohighlight">\(\mathcal{N}\)</span> is the normal distribution:</p>
<ul class="simple">
<li><p>one dimension: <span class="math notranslate nohighlight">\(N(x, \mu, \sigma) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left( \frac{-(x-\mu)^2}{2 \sigma ^2} \right)\)</span></p></li>
<li><p>multi-dimensional: <span class="math notranslate nohighlight">\(N(\vec{x}, \vec{\mu}, \underline{\underline{\Sigma}}) = \frac{1}{(2 \pi |\underline{\underline{\Sigma}}|)} \exp \left( \frac{1}{2} (\vec{x} - \vec{\mu})^T \underline{\underline{\Sigma}}^{-1}  (\vec{x} - \vec{\mu}) \right)\)</span></p></li>
</ul>
<p>where <span class="math notranslate nohighlight">\(\underline{\underline{\Sigma}}\)</span> is the covariance matrix.</p>
<section id="expectation-step">
<h4><span class="section-number">7.5.4.3.1. </span>Expectation step:<a class="headerlink" href="#expectation-step" title="Permalink to this heading">#</a></h4>
<p>We can calculate the expected probability that a point <span class="math notranslate nohighlight">\(i\)</span> is in a cluster <span class="math notranslate nohighlight">\(k\)</span> with the following formula for a 1D Gaussian:</p>
<p><span class="math notranslate nohighlight">\(\gamma_{ik} = \frac{\phi_k \mathcal{N}(\vec{x}_i, \vec{\mu}_k, \vec{\sigma}_k)}{\sum_j \phi_j \mathcal{N}(\vec{x}_i, \vec{\mu}_j, \vec{\sigma}_j)}\)</span></p>
</section>
<section id="maximization-step">
<h4><span class="section-number">7.5.4.3.2. </span>Maximization step:<a class="headerlink" href="#maximization-step" title="Permalink to this heading">#</a></h4>
<p>The parameters of the distributions can then be updated by calculating the maximum likelihood estimators for <span class="math notranslate nohighlight">\(\phi\)</span>, <span class="math notranslate nohighlight">\(\mu\)</span>, and <span class="math notranslate nohighlight">\(\sigma\)</span>, similar to the way these parameters would be estimated for a single distribution:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\phi_k = \sum_{i=1}^N \frac{\gamma_{ik}}{N}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mu_k = \frac{\sum_{i=1}^N \gamma_{ik} x_i}{\sum_{i=1}^N \gamma_{ik}} \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_k = \frac{\sum_{i=1}^N \gamma_{ik} (x_i - \mu_k)^2}{\sum_{i=1}^N \gamma_{ik}} \)</span></p></li>
</ul>
<p>These parameters are derived by maximizing <span class="math notranslate nohighlight">\(P(\vec{x})\)</span> with respect to each parameter. The formulas for multi-dimensional Gaussians are derived in the same way but are more complex.</p>
<a class="reference internal image-reference" href="../_images/GMM.gif"><img alt="../_images/GMM.gif" src="../_images/GMM.gif" style="width: 500px;" /></a>
<p>Gaussian mixture models are much more flexible than k-means models because they have different variances and covariances between clusters. Let’s see how GMM’s perform for some of the earlier datasets:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>

<span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">covariance_type</span> <span class="o">=</span> <span class="s1">&#39;full&#39;</span> <span class="c1">#full, tied, spherical</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="n">X_i</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">covariance_type</span> <span class="o">=</span> <span class="n">covariance_type</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_i</span><span class="p">)</span>
    <span class="n">y_predict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_i</span><span class="p">)</span>
    <span class="n">centers</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">means_</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_i</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_i</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">y_predict</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">center</span> <span class="ow">in</span> <span class="n">centers</span><span class="p">:</span>
        <span class="n">x_i</span> <span class="o">=</span> <span class="n">center</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y_i</span> <span class="o">=</span> <span class="n">center</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">y_i</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/66b20402d175a76402fe45c517f79b32c059b11d44121072eddfd3d09976d7e1.png" src="../_images/66b20402d175a76402fe45c517f79b32c059b11d44121072eddfd3d09976d7e1.png" />
</div>
</div>
<p>Note that we set the covariance type to <code class="docutils literal notranslate"><span class="pre">full</span></code>. This means that all entries in the covariance matrix are optimized during the “maximization” step. Selecting “tied” means that only the diagonal elements of the covariance matrix will be non-zero, and selecting “spherical” means that only diagonal elements will be non-zero and they will all be equal. Using <code class="docutils literal notranslate"><span class="pre">full</span></code> provides the most parameters to optimize, but also takes the longest and is most sensitive to initial guesses. Using <code class="docutils literal notranslate"><span class="pre">spherical</span></code> is very similar to k-means.</p>
<p>GMM’s have the same weakness as k-means since we need to know the number of clusters beforehand. One way to be more quantitative is to assess a metric such as the Silhouette score as a function of number of clusters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span><span class="p">,</span> <span class="n">calinski_harabasz_score</span>

<span class="n">X_i</span> <span class="o">=</span> <span class="n">X_pca</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">covariance_type</span> <span class="o">=</span> <span class="n">covariance_type</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_i</span><span class="p">)</span>
<span class="n">y_predict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_i</span><span class="p">)</span>

<span class="n">silhouette</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">)</span>
<span class="n">c_h_score</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">silhouette</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">c_h_score</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.3889340481198901
5375.873303272862
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="example-plot-the-silhouette-score-as-a-function-of-number-of-clusters-for-a-gmm-model-on-the-pca-dataset">
<h3><span class="section-number">7.5.4.4. </span>Example: Plot the silhouette score as a function of number of clusters for a GMM model on the PCA dataset<a class="headerlink" href="#example-plot-the-silhouette-score-as-a-function-of-number-of-clusters-for-a-gmm-model-on-the-pca-dataset" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_clusters_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">silhouette_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">n_clusters_list</span><span class="p">:</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_i</span><span class="p">)</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_i</span><span class="p">)</span>
    
    <span class="n">silhouette</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>
    <span class="n">silhouette_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silhouette</span><span class="p">)</span>
    
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">),</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">150</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_clusters_list</span><span class="p">,</span> <span class="n">silhouette_list</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;# of clusters&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;silhouette score&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">n_clusters_list</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d37d003341d699807a9309b7c460ee52a979752424d9eafde81762b6b5991c8c.png" src="../_images/d37d003341d699807a9309b7c460ee52a979752424d9eafde81762b6b5991c8c.png" />
</div>
</div>
<p>One additional difference between GMM’s and k-means is that GMM’s support “mixed membership”. GMM’s assign points to clusters by selecting the cluster that a point has the highest probability of belonging to. However, we can also check the probabilities for all clusters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">probabilities</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_i</span><span class="p">)</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_i</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Probabilities shape: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">probabilities</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Clusters shape: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">clusters</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">((</span><span class="n">probabilities</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">clusters</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Probabilities shape: (2060, 10)
Clusters shape: (2060,)
(array([0.00000000e+00, 1.59901044e-01, 1.85204790e-05, 8.73882805e-82,
       0.00000000e+00, 7.90943391e-08, 0.00000000e+00, 8.35967386e-01,
       2.87052747e-32, 4.11297046e-03]), 7)
</pre></div>
</div>
</div>
</div>
<p>We can see that the predicted cluster is the one with the highest probability:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">point_idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">),</span> <span class="n">probabilities</span><span class="p">[</span><span class="n">point_idx</span><span class="p">,</span> <span class="p">:])</span>
<span class="c1">#ax.plot([clusters[point_idx], clusters[point_idx]], [0, 1])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Cluster&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2a855c04503f489cee2a618488fd085b92c66bc9b1e91cb5cd4b42f58f0743ca.png" src="../_images/2a855c04503f489cee2a618488fd085b92c66bc9b1e91cb5cd4b42f58f0743ca.png" />
</div>
</div>
<p>However, there is also a non-zero probability that the point is in other clusters (cluster number 7 in this case). We can use this to figure out which points are well-clustered and which ones are not:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">well_defined</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">X_i</span><span class="p">:</span>
    <span class="n">point</span> <span class="o">=</span> <span class="n">point</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">probs</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.95</span><span class="p">:</span>
        <span class="n">well_defined</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">point</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>

<span class="n">X_welldefined</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">well_defined</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_welldefined</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">y_welldefined</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_welldefined</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_i</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_i</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">y_predict</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;All points&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_welldefined</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_welldefined</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">y_welldefined</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Well defined points&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x_0$&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(660, 2)
</pre></div>
</div>
<img alt="../_images/4e80fc04633923928d49a50b66a308b7b353cde3bf7ae3ec87429c15c2cf5609.png" src="../_images/4e80fc04633923928d49a50b66a308b7b353cde3bf7ae3ec87429c15c2cf5609.png" />
</div>
</div>
<p>Of course, the silhoutte scores should be much higher for these “well defined” clusters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">silhouette</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_i</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">)</span>
<span class="n">silhouette_welldefined</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X_welldefined</span><span class="p">,</span> <span class="n">y_welldefined</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Silhouette score for all points: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">silhouette</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Silhouette score for well-defined points: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">silhouette_welldefined</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Silhouette score for all points: 0.3889340481198901
Silhouette score for well-defined points: 0.6344883005388762
</pre></div>
</div>
</div>
</div>
<p>Another advantage of GMM’s is that they have some built-in statistical measures. For example, we can compute the Bayesian information critera for the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">bic</span><span class="p">(</span><span class="n">X_i</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>12428.380003864966
</pre></div>
</div>
</div>
</div>
<p>We will cover more details of the BIC and other advanced features of GMM’s when we discuss generative models.</p>
</section>
</section>
<section id="density-based-models">
<h2><span class="section-number">7.5.5. </span>Density-based models<a class="headerlink" href="#density-based-models" title="Permalink to this heading">#</a></h2>
<p>Density-based clustering algorithms consider local density of points and utilize this information to group points into clusters.</p>
<section id="mean-shift-algorithm">
<h3><span class="section-number">7.5.5.1. </span>Mean shift algorithm<a class="headerlink" href="#mean-shift-algorithm" title="Permalink to this heading">#</a></h3>
<p>The simplest density-based algorithm is the “mean shift” algorithm. This is similar to k-means in that we seek the centroid of each cluster. The difference is that in mean shift the number of clusters does not need to be specified. Instead a “window” is specified, and at each iteration the centroids are updated to centroid of all points in each window. Let’s see how this works for a single point:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_distance</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
    <span class="c1"># we will use the numpy 2-norm to calculate Euclidean distance:</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x1</span><span class="o">-</span><span class="n">x2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1">#&lt;- the 2 is optional here since 2 is the default.</span>

<span class="k">def</span> <span class="nf">get_nearby_points</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_list</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
    <span class="c1"># r is the radius</span>
    <span class="n">dist_pairs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">xi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x_list</span><span class="p">):</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">get_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">xi</span><span class="p">)</span>
        <span class="n">dist_pairs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">dist</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">xi</span><span class="p">])</span> <span class="c1">#&lt;- gives us the distance for each point</span>
    <span class="n">in_window</span> <span class="o">=</span> <span class="p">[</span><span class="n">pt</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">pt</span> <span class="ow">in</span> <span class="n">dist_pairs</span> <span class="k">if</span> <span class="n">pt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">r</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">in_window</span>

<span class="k">def</span> <span class="nf">get_new_centroid</span><span class="p">(</span><span class="n">old_centroid</span><span class="p">,</span> <span class="n">x_list</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
    <span class="n">in_range</span> <span class="o">=</span> <span class="n">get_nearby_points</span><span class="p">(</span><span class="n">old_centroid</span><span class="p">,</span> <span class="n">x_list</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_range</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">new_centroid</span> <span class="o">=</span> <span class="n">old_centroid</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">new_centroid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">in_range</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_centroid</span>
</pre></div>
</div>
</div>
</div>
<p>Note the similarity to the kNN functions for prior lectures. It is a good idea to “abstract out” the distance function so that we could try other distance metrics easily.</p>
<p>Let’s apply this to a single point in a dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">guess</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1">#&lt;- set an initial guess</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">X_pca</span><span class="p">[::</span><span class="mi">3</span><span class="p">]</span> <span class="c1">#take every third point to speed things up</span>
<span class="n">r</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">nearby</span> <span class="o">=</span> <span class="n">get_nearby_points</span><span class="p">(</span><span class="n">guess</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="n">nearby</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nearby</span><span class="p">)</span>
<span class="n">new</span> <span class="o">=</span> <span class="n">get_new_centroid</span><span class="p">(</span><span class="n">guess</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">nearby</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">nearby</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">guess</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">guess</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Mean Shift Clustering - 1st Run&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Old Center&#39;</span><span class="p">,</span> <span class="s1">&#39;New Center&#39;</span><span class="p">,</span> <span class="s1">&#39;Entire Data Points&#39;</span><span class="p">,</span> <span class="s1">&#39;Points nearby the Center&#39;</span><span class="p">])</span>

<span class="n">guess</span> <span class="o">=</span> <span class="n">new</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d1031513cb8e3d2a3eec8ae2755d1b88c05bbbe6ae6ce4ea2b4f6c923f971d2d.png" src="../_images/d1031513cb8e3d2a3eec8ae2755d1b88c05bbbe6ae6ce4ea2b4f6c923f971d2d.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nearby</span> <span class="o">=</span> <span class="n">get_nearby_points</span><span class="p">(</span><span class="n">guess</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="n">nearby</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nearby</span><span class="p">)</span>
<span class="n">new</span> <span class="o">=</span> <span class="n">get_new_centroid</span><span class="p">(</span><span class="n">guess</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">nearby</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">nearby</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">guess</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">guess</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Mean Shift Clustering - 2nd Run&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Old Center&#39;</span><span class="p">,</span> <span class="s1">&#39;New Center&#39;</span><span class="p">,</span> <span class="s1">&#39;Entire Data Points&#39;</span><span class="p">,</span> <span class="s1">&#39;Points nearby the Center&#39;</span><span class="p">])</span>

<span class="n">guess</span> <span class="o">=</span> <span class="n">new</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/5e511af7ebfda8ff04de2b563d943434ae6c00e605c5358fb8cb140bdf3a1315.png" src="../_images/5e511af7ebfda8ff04de2b563d943434ae6c00e605c5358fb8cb140bdf3a1315.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nearby</span> <span class="o">=</span> <span class="n">get_nearby_points</span><span class="p">(</span><span class="n">guess</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="n">nearby</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nearby</span><span class="p">)</span>
<span class="n">new</span> <span class="o">=</span> <span class="n">get_new_centroid</span><span class="p">(</span><span class="n">guess</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">nearby</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">nearby</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">guess</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">guess</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">mec</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Mean Shift Clustering - 3rd Run&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Old Center&#39;</span><span class="p">,</span> <span class="s1">&#39;New Center&#39;</span><span class="p">,</span> <span class="s1">&#39;Entire Data Points&#39;</span><span class="p">,</span> <span class="s1">&#39;Points nearby the Center&#39;</span><span class="p">])</span>

<span class="n">guess</span> <span class="o">=</span> <span class="n">new</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/57c926af211fdc9cd5b09d3293c8d7e0eb87da8bb16b644cf2f00a62b7bae650.png" src="../_images/57c926af211fdc9cd5b09d3293c8d7e0eb87da8bb16b644cf2f00a62b7bae650.png" />
</div>
</div>
<p>Re-run the block above to watch the point converge. You can play with the initial guess to see how it changes things.</p>
</section>
<section id="discussion-what-happens-if-the-initial-guess-is-very-far-away-from-a-cluster">
<h3><span class="section-number">7.5.5.2. </span>Discussion: What happens if the initial guess is very far away from a cluster?<a class="headerlink" href="#discussion-what-happens-if-the-initial-guess-is-very-far-away-from-a-cluster" title="Permalink to this heading">#</a></h3>
<blockquote>
<div><p>There will be no points within the radius (or <code class="docutils literal notranslate"><span class="pre">bandwidth</span></code>) and this algorithm is not going to work. Change the initial guess to [10, 0] and rerun the algorithm. You will notice that the <code class="docutils literal notranslate"><span class="pre">nearby</span></code> list is empty.</p>
</div></blockquote>
<p>We see that the mean shift algorithm causes an initial guess for a centroid to move toward a point of higher density. However, it isn’t clear exactly how to get initial guesses. If we choose random points then some will have no points around them and not move. It also isn’t clear how to decide how many initial guess points we should use.</p>
<p>The solution to this is to use each point of the dataset as an initial guess!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">centroids</span> <span class="o">=</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mean_shift_iteration</span><span class="p">(</span><span class="n">x_list</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">centroid</span> <span class="ow">in</span> <span class="n">x_list</span><span class="p">:</span>
        <span class="n">new</span> <span class="o">=</span> <span class="n">get_new_centroid</span><span class="p">(</span><span class="n">centroid</span><span class="p">,</span> <span class="n">x_list</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
        <span class="n">centroids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">centroids</span>

<span class="n">new_centroids</span> <span class="o">=</span> <span class="n">mean_shift_iteration</span><span class="p">(</span><span class="n">centroids</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>

<span class="n">news</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_centroids</span><span class="p">)</span>
<span class="n">olds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">olds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">olds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">news</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">news</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Mean Shift Clustering - 1st Run&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Entire Data Points&#39;</span><span class="p">,</span> <span class="s1">&#39;Old Center&#39;</span><span class="p">,</span> <span class="s1">&#39;New Center&#39;</span><span class="p">])</span>

<span class="n">centroids</span> <span class="o">=</span> <span class="n">new_centroids</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ce23ab5dc04d2e723828fc3629358778e791cb282b02be98145fc0ec9d96c24d.png" src="../_images/ce23ab5dc04d2e723828fc3629358778e791cb282b02be98145fc0ec9d96c24d.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_centroids</span> <span class="o">=</span> <span class="n">mean_shift_iteration</span><span class="p">(</span><span class="n">centroids</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>

<span class="n">news</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_centroids</span><span class="p">)</span>
<span class="n">olds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">olds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">olds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">news</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">news</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Mean Shift Clustering - 2nd Run&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Entire Data Points&#39;</span><span class="p">,</span> <span class="s1">&#39;Old Center&#39;</span><span class="p">,</span> <span class="s1">&#39;New Center&#39;</span><span class="p">])</span>

<span class="n">centroids</span> <span class="o">=</span> <span class="n">new_centroids</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2e7ae2915580fbe540b782554054031744074b718762347bdda34a57ba1d7ab0.png" src="../_images/2e7ae2915580fbe540b782554054031744074b718762347bdda34a57ba1d7ab0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_centroids</span> <span class="o">=</span> <span class="n">mean_shift_iteration</span><span class="p">(</span><span class="n">centroids</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>

<span class="n">news</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_centroids</span><span class="p">)</span>
<span class="n">olds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">olds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">olds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">news</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">news</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Mean Shift Clustering - 3rd Run&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Entire Data Points&#39;</span><span class="p">,</span> <span class="s1">&#39;Old Center&#39;</span><span class="p">,</span> <span class="s1">&#39;New Center&#39;</span><span class="p">])</span>

<span class="n">centroids</span> <span class="o">=</span> <span class="n">new_centroids</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/880ddb9971714b9b64f6e57eebe4ff8b90efba2017827c3dcece60efcfc30ef8.png" src="../_images/880ddb9971714b9b64f6e57eebe4ff8b90efba2017827c3dcece60efcfc30ef8.png" />
</div>
</div>
<p>To complete the algorithm we just need to iterate until the new centrods are the same as the old centroids, and assign points to the nearest centroid:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mean_shift_clustering</span><span class="p">(</span><span class="n">x_list</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">tolerance</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">):</span>
    <span class="c1"># tolerance will define when new and old centroids are the same.</span>
    <span class="n">old_centroids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_list</span><span class="p">)</span>
    <span class="n">new_centroids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x_list</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">old_centroids</span> <span class="o">-</span> <span class="n">new_centroids</span><span class="p">)</span>
    <span class="k">while</span> <span class="n">delta</span> <span class="o">&gt;=</span> <span class="n">tolerance</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Working: delta = </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">delta</span><span class="p">))</span>
        <span class="n">new_centroids</span> <span class="o">=</span> <span class="n">mean_shift_iteration</span><span class="p">(</span><span class="n">old_centroids</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">old_centroids</span> <span class="o">-</span> <span class="n">new_centroids</span><span class="p">)</span>
        <span class="n">old_centroids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_centroids</span><span class="p">)</span>
        
    <span class="n">unique_centroids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">centroid</span> <span class="ow">in</span> <span class="n">new_centroids</span><span class="p">:</span>
        <span class="n">unique</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">for</span> <span class="n">uc</span> <span class="ow">in</span> <span class="n">unique_centroids</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">uc</span> <span class="o">-</span> <span class="n">centroid</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">tolerance</span><span class="p">:</span>
                <span class="n">unique</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">unique</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">unique_centroids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">centroid</span><span class="p">)</span>
            
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pt</span> <span class="ow">in</span> <span class="n">x_list</span><span class="p">:</span>
        <span class="n">min_dist</span> <span class="o">=</span> <span class="mf">1e99</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">centroid</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">unique_centroids</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">get_distance</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span><span class="n">centroid</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">min_dist</span><span class="p">:</span>
                <span class="n">label</span> <span class="o">=</span> <span class="n">j</span>
                <span class="n">min_dist</span> <span class="o">=</span> <span class="n">get_distance</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span><span class="n">centroid</span><span class="p">)</span>
        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
            
    <span class="k">return</span> <span class="n">labels</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">unique_centroids</span><span class="p">)</span>

<span class="n">r</span> <span class="o">=</span> <span class="mi">15</span>
<span class="o">%</span><span class="k">time</span> labels, centroids = mean_shift_clustering(X, r)

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centroids</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centroids</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">120</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">edgecolors</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Working: delta = 137.41
Working: delta = 65.42
Working: delta = 4.03
CPU times: user 13.6 s, sys: 83 ms, total: 13.7 s
Wall time: 13.7 s
</pre></div>
</div>
<img alt="../_images/fb2d3261830b07e669a43d50714e3ddd50976b43578b7fcf684c82340f0bc605.png" src="../_images/fb2d3261830b07e669a43d50714e3ddd50976b43578b7fcf684c82340f0bc605.png" />
</div>
</div>
</section>
<section id="discussion-how-can-we-modify-the-algorithm-to-find-more-clusters">
<h3><span class="section-number">7.5.5.3. </span>Discussion: How can we modify the algorithm to find more clusters?<a class="headerlink" href="#discussion-how-can-we-modify-the-algorithm-to-find-more-clusters" title="Permalink to this heading">#</a></h3>
<blockquote>
<div><p>In mean shift algorithm, the number of clusters is implicitly defined by the radius of window. To find more clusters, the radius should be smaller so that we get more clusters with smaller sizes.</p>
</div></blockquote>
<p>Let’s compare our mean shift algorithm to the one from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">MeanShift</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MeanShift</span><span class="p">(</span><span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">21</span><span class="p">)</span>
<span class="o">%</span><span class="k">time</span> model.fit(X_tsne)
<span class="n">labels</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">centroids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cluster_centers_</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_tsne</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_tsne</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">labels</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centroids</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centroids</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">120</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 10.7 s, sys: 185 ms, total: 10.9 s
Wall time: 11 s
</pre></div>
</div>
<img alt="../_images/62f1026edcbbb48f8a464c6c080909408d80916d9745d1c708c3ec28f248f90f.png" src="../_images/62f1026edcbbb48f8a464c6c080909408d80916d9745d1c708c3ec28f248f90f.png" />
</div>
</div>
<p>We see that the results are the same, but <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> is much faster. One note is that <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> uses some slightly different techniques to speed things up, so <code class="docutils literal notranslate"><span class="pre">bandwidth</span></code> is not the same as <code class="docutils literal notranslate"><span class="pre">radius</span></code>. However, the results are generally similar and the concept is the same.</p>
</section>
<section id="dbscan">
<h3><span class="section-number">7.5.5.4. </span>DBSCAN<a class="headerlink" href="#dbscan" title="Permalink to this heading">#</a></h3>
<p>The DBSCAN algorithm also uses a local sliding window similar to mean shift, but instead of defining clusters by centroids it defines the cluster by whether or not a point falls within the sliding window. We will not go through the algorithm in detail, but the general steps are:</p>
<ol class="arabic simple">
<li><p>Start with a random point and find its neigbhors within distance <span class="math notranslate nohighlight">\(r\)</span>.</p></li>
<li><p>If there are a sufficient number of neigbhors (defined by a minimum points argument) then the clustering process starts. If not then the point is labeled as noise and a new point is selected until the clustering process starts.</p></li>
<li><p>The neighbors within a distance <span class="math notranslate nohighlight">\(r\)</span> are added to the cluster.</p></li>
<li><p>The nearest neighbor is selected as the next point, and the same process is repeated until all points within distance <span class="math notranslate nohighlight">\(r\)</span> of any point within a cluster are defined as being part of that cluster.</p></li>
<li><p>Once a cluster has finished, a new point is selected and a new cluster is started. The process is repeated until all points have been assigned to a cluster or labeled as noise.</p></li>
</ol>
<p>The key hyperparameters are:</p>
<ul class="simple">
<li><p><strong>r</strong>: the radius to include in a cluster</p></li>
<li><p><strong>min_samples</strong>: the minimum number of samples within a radius of <span class="math notranslate nohighlight">\(\epsilon\)</span> such that a point is not considered noise.</p></li>
</ul>
<p>The following animation illustrates how the DBSCAN algorithm works:</p>
<a class="reference internal image-reference" href="../_images/DBSCAN.gif"><img alt="../_images/DBSCAN.gif" src="../_images/DBSCAN.gif" style="width: 500px;" /></a>
<p>The main advantage of DBSCAN is that it can find clusters defined by highly non-linear boundaries, unlike k-means, mean shift, or even GMM’s. Let’s see how the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> implementation works:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">X_pca</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">min_samples</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">y_predict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">y_predict</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;DBSCAN for PCA Data&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c1a921a9bd2ff36bc0b69f491423e92cd1fc4f6334cb4da9c5ed9489081675eb.png" src="../_images/c1a921a9bd2ff36bc0b69f491423e92cd1fc4f6334cb4da9c5ed9489081675eb.png" />
</div>
</div>
<p>Note that the clustering can be very sensitive to the hyperparameters! These hyperparameters will be related to the density of points, so you may be able to get a good guess based on intuition about the data or by looking at the data. However, some tuning is nearly always necessary.</p>
<p>It is also not possible to predict the cluster of a new point with DBSCAN, which can be a major weakness. One potential solution is to use the DBSCAN output as “classes” and train a classification model, though this adds complexity and the classification model may not be accurate.</p>
</section>
</section>
<section id="hierarchical-models">
<h2><span class="section-number">7.5.6. </span>Hierarchical models<a class="headerlink" href="#hierarchical-models" title="Permalink to this heading">#</a></h2>
<p>The final type of clustering we will discuss are “hierarchical” models. These models construct linkages between different points and use distance cutoffs to assign clusters. Examining the hierarchy of points is a useful way to get insight into the structure of a high-dimensional dataset without dimensional reduction. The downside is that it can be rather slow, since the algorithms scale as <span class="math notranslate nohighlight">\(N^3\)</span>. However, for the relatively small sizes of datasets typically encountered in engineering it is usually feasible to construct these hierarchies.</p>
<section id="dendrograms">
<h3><span class="section-number">7.5.6.1. </span>Dendrograms<a class="headerlink" href="#dendrograms" title="Permalink to this heading">#</a></h3>
<p>A “dendrogram” is a graphical representation of the distances between different points in some high-dimensional space. One intuitive but qualitative example of a dendrogram are the <a class="reference external" href="https://www.instituteofcaninebiology.org/how-to-read-a-dendrogram.html">species trees</a> commonly used in biology:</p>
<a class="reference internal image-reference" href="../_images/bio_dendrogram.png"><img alt="../_images/bio_dendrogram.png" src="../_images/bio_dendrogram.png" style="width: 500px;" /></a>
<p>We can see that it is possible to create different “clusters” of species based on different defining characteristics. By choosing more or less specific “cutoffs” we could create a few large clusters or many small clusters. The idea is similar for data sets. Let’s see how it looks for some of our examples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">dendrogram</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">X_pca</span>

<span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;single&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Lets take a closer look at the “linkage” output:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X shape: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Z shape: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">Z</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Z[0]:&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>X shape: (2060, 2)
Z shape: (2059, 4)
Z[0]: [6.77000000e+02 6.91000000e+02 9.83256746e-04 2.00000000e+00]
</pre></div>
</div>
</div>
</div>
<p>The “linkage” output has 4 members. Each entry corresponds to the formation of a new cluster from smaller clusters, hence there are (n-1) entries (since the first entry involves 2 points, and each iteration adds one more point).</p>
<ul class="simple">
<li><p>the first two entries are the index of the two points/clusters that are being combined (point 677 and 691)</p></li>
<li><p>the third entry is the distance between these clusters (0.00098)</p></li>
<li><p>the fourth entry is the total number of points in the new cluster (2 in this case)</p></li>
</ul>
<p>Note that we passed a “method” argument into the linkage. This describes the method that is used to calculate the distance between two clusters that have multiple points. There are more details available <a class="reference external" href="https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage">here</a>, but a very qualitative descripton of some of the options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">single</span></code>: take the minimum distance between any two points in the two clusters</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">complete</span></code>: take the maximum distance between any two points in the two clusters</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">average</span></code>: use an average of distances between points in the two clusters</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weighted</span></code>: weight distances differently between the agglomerated cluster and one being added</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">centriod</span></code>: use the distance between cluster centroids</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ward</span></code>: use the distance that minimizes the variance between the clusters</p></li>
</ul>
<p>So, which one should we choose? This is where we can use the “cophenetic coefficient”, which measures the ratio of the distance in “linkage” space to the distance in the high-dimensional space.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">cophenet</span>
<span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">pdist</span>

<span class="n">Dij</span> <span class="o">=</span> <span class="n">pdist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;single&#39;</span><span class="p">,</span> <span class="s1">&#39;complete&#39;</span><span class="p">,</span> <span class="s1">&#39;average&#39;</span><span class="p">,</span> <span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="s1">&#39;centroid&#39;</span><span class="p">,</span> <span class="s1">&#39;ward&#39;</span><span class="p">]:</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="n">method</span><span class="p">)</span>
    <span class="n">C</span><span class="p">,</span> <span class="n">coph_dists</span> <span class="o">=</span> <span class="n">cophenet</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">Dij</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;cophenetic coefficient of </span><span class="si">{}</span><span class="s1">: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">C</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cophenetic coefficient of single: 0.9549424125877355
cophenetic coefficient of complete: 0.9332039766375549
cophenetic coefficient of average: 0.9781265675460892
cophenetic coefficient of weighted: 0.9568082912812889
cophenetic coefficient of centroid: 0.9786287346144893
cophenetic coefficient of ward: 0.8212908347506772
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">dendrogram</span></code> function is a visual representation of this “linkage” structure. The “color threshold” tells the dendrogram a distance (y-axis value) below which to identify separate branches of the dendrogram as different colors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;centroid&#39;</span><span class="p">)</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">color_threshold</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;PCA Data&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Dendrogram&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/8435f6ea9a7343fcc2ec01ed7a05cec24ac1b54c3dc00b292b4a9bd1d0e7e0fe.png" src="../_images/8435f6ea9a7343fcc2ec01ed7a05cec24ac1b54c3dc00b292b4a9bd1d0e7e0fe.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">color_threshold</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Dendrogram&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/fe7b86ccf742e217331bd31fff1032af701f9461d6ae649b1594c4791bcd2175.png" src="../_images/fe7b86ccf742e217331bd31fff1032af701f9461d6ae649b1594c4791bcd2175.png" />
</div>
</div>
<p>Sometimes it is easier to not show every single datapoint, and truncate the dendrogram:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">color_threshold</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">truncate_mode</span> <span class="o">=</span> <span class="s1">&#39;lastp&#39;</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;PCA Data&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Truncated Dendrogram&#39;</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="mi">37</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[7.58000000e+02 1.93700000e+03 6.38691346e-03 2.00000000e+00]
</pre></div>
</div>
<img alt="../_images/f41f61723efee383fb02e222cff6d9e249e08ce40a6bb8ffa2c0e10a1ba1edb3.png" src="../_images/f41f61723efee383fb02e222cff6d9e249e08ce40a6bb8ffa2c0e10a1ba1edb3.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">color_threshold</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">truncate_mode</span> <span class="o">=</span> <span class="s1">&#39;lastp&#39;</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Truncated Dendrogram&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6bacb2bc7e7ac2e92c4d50e371fc86beea683e81d64d42bbbf7ceea470b872b0.png" src="../_images/6bacb2bc7e7ac2e92c4d50e371fc86beea683e81d64d42bbbf7ceea470b872b0.png" />
</div>
</div>
</section>
<section id="agglomerative-hierarchical-clustering">
<h3><span class="section-number">7.5.6.2. </span>Agglomerative hierarchical clustering<a class="headerlink" href="#agglomerative-hierarchical-clustering" title="Permalink to this heading">#</a></h3>
<p>Agglomerative clustering is easy to understand once the “linkage” structure makes sense. The number of clusters can be defined either explicitly (move up the tree until there are ‘k’ clusters) or implicitly (provide a linkage distance that defines separate clusters).</p>
<p>The following animations illustrates this nicely:</p>
<a class="reference internal image-reference" href="../_images/agglomerative.gif"><img alt="../_images/agglomerative.gif" src="../_images/agglomerative.gif" style="width: 700px;" /></a>
<p>The mechanics of doing this can be a little tricky, but luckily there are built-in functions to help:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">fcluster</span>

<span class="n">max_d</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">clusters_dist</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">max_d</span><span class="p">,</span> <span class="n">criterion</span> <span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">)</span>
<span class="n">clusters_k</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">criterion</span> <span class="o">=</span> <span class="s1">&#39;maxclust&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">color_threshold</span> <span class="o">=</span> <span class="n">max_d</span><span class="p">,</span> <span class="n">truncate_mode</span> <span class="o">=</span> <span class="s1">&#39;lastp&#39;</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">k</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">clusters_dist</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">clusters_k</span><span class="p">])</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Truncated Dendrogram&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Agglomerative Clustering w/ criterion = &#39;distance&#39;&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Agglomerative Clustering w/ criterion = &#39;maxclust&#39;&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/0b59b933d95bfb3175488fc25c5e5fda7e7cd83d5e50d14249c77af31d1b2994.png" src="../_images/0b59b933d95bfb3175488fc25c5e5fda7e7cd83d5e50d14249c77af31d1b2994.png" />
</div>
</div>
<p>There are options for determining the cutoffs automatically, but none of them are great! The most common is the inconsistency method, which monitors for “jumps” in the distance:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(I = \frac{h-avg}{std}\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(h\)</span>: merge height of cluster (length in y-directon on dendrogram)</p></li>
<li><p><span class="math notranslate nohighlight">\(avg\)</span>: average height of last <span class="math notranslate nohighlight">\(d\)</span> merges</p></li>
<li><p><span class="math notranslate nohighlight">\(std\)</span>: standard deviation of last <span class="math notranslate nohighlight">\(d\)</span> merges</p></li>
</ul>
</li>
</ul>
<p>If <span class="math notranslate nohighlight">\(I &gt;= t\)</span> where t is a specified threshold then this will be used as the cutoff. Let’s see how it performs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">I_cutoff</span> <span class="o">=</span> <span class="mi">9</span>
<span class="n">clusters_I</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">I_cutoff</span><span class="p">,</span> <span class="n">criterion</span> <span class="o">=</span> <span class="s1">&#39;inconsistent&#39;</span><span class="p">,</span> <span class="n">depth</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">clusters_I</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">color_threshold</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">truncate_mode</span> <span class="o">=</span> <span class="s1">&#39;lastp&#39;</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">),</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">clusters_I</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">clusters_dist</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">clrs</span><span class="p">[</span><span class="n">clusters_k</span><span class="p">])</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Truncated Dendrogram&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Agglomerative Clustering w/ criterion = &#39;inconsistent&#39;&quot;</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Agglomerative Clustering w/ criterion = &#39;distance&#39;&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Agglomerative Clustering w/ criterion = &#39;maxclust&#39;&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of clusters:&#39;</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of clusters: 5
</pre></div>
</div>
<img alt="../_images/8dfdc103a7205bc8ab0f117ec19e90658c8f66f8a7e4ddc86aeff752be3712c3.png" src="../_images/8dfdc103a7205bc8ab0f117ec19e90658c8f66f8a7e4ddc86aeff752be3712c3.png" />
</div>
</div>
<p>In practice it is typically best to use some visualization strategy in conjunction with manual and/or automatic strategies to determine a cutoff that makes intuitive sense.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="ML_2_3_Alternate_Classification_Models.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">7.4. </span>Alternate classification methods</p>
      </div>
    </a>
    <a class="right-next"
       href="ML_2_5_Generative_Models.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">7.6. </span>Generative Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-overview">7.5.1. Clustering Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">7.5.1.1. Problem statement</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-problems-algorithms">7.5.1.2. Types of problems/algorithms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy-and-distance-metrics">7.5.2. Accuracy and distance metrics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-preparation">7.5.3. Dataset Preparation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-maximization-models">7.5.4. Expectation-maximization models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means">7.5.4.1. k-means</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion-which-of-these-clusters-might-be-outliers">7.5.4.2. Discussion: Which of these clusters might be outliers?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-mixture-models">7.5.4.3. Gaussian mixture models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-step">7.5.4.3.1. Expectation step:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#maximization-step">7.5.4.3.2. Maximization step:</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-plot-the-silhouette-score-as-a-function-of-number-of-clusters-for-a-gmm-model-on-the-pca-dataset">7.5.4.4. Example: Plot the silhouette score as a function of number of clusters for a GMM model on the PCA dataset</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#density-based-models">7.5.5. Density-based models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-shift-algorithm">7.5.5.1. Mean shift algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion-what-happens-if-the-initial-guess-is-very-far-away-from-a-cluster">7.5.5.2. Discussion: What happens if the initial guess is very far away from a cluster?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion-how-can-we-modify-the-algorithm-to-find-more-clusters">7.5.5.3. Discussion: How can we modify the algorithm to find more clusters?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dbscan">7.5.5.4. DBSCAN</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hierarchical-models">7.5.6. Hierarchical models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dendrograms">7.5.6.1. Dendrograms</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#agglomerative-hierarchical-clustering">7.5.6.2. Agglomerative hierarchical clustering</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Medford Group
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>